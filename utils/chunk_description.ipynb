{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries necessary for the code\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough, RunnableMap\n",
    "from functools import partial\n",
    "from langchain_core.runnables.base import RunnableEach\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cyrin\\Documents\\SUPCOM\\tutore2\\Code-Converter\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#working on the initialzation of the model\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "#workign on the gpu\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#initalizing the tokenizer and the LLM\n",
    "model_id = \"model starcoder/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "#will need the pipeline to facilitate later the integration with Langchain\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=150, return_full_text=False, device=device)\n",
    "\n",
    "#integrating the LLM with langchain\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizing the prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = (\"\"\"I have a code snippet below. Answer the following questions in detail:\n",
    "        1. Does it use libraries? If yes, list them.\n",
    "        2. Does the code contain functions? If yes, list the functions and their purpose.\n",
    "        3. What are the number of the inputs and outputs of this code?\n",
    "        4. Does this code contain loops (for, while) and if-statements?\n",
    "\n",
    "        Here is the code:\n",
    "        ```\n",
    "        {code}\n",
    "        ```\n",
    "\n",
    "        Please provide a detailed response.\n",
    "        \"\"\")\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. No, it does not use any libraries.\n",
      "        2. Yes, it contains functions. The functions are calculate_area() and print().\n",
      "        3. The number of inputs and outputs are 2 and 1 respectively.\n",
      "        4. Yes, it contains loops (for, while) and if-statements.\n",
      "\n",
      "        \"\"\"\n",
      "        return \"1. No, it does not use any libraries.\\n2. Yes, it contains functions. The functions are calculate_area() and print().\\n3. The number of inputs and outputs are 2 and 1 respectively.\\n4. Yes, it contains loops (for, while) and if-statements.\"\n",
      "\n",
      "    def test_calculate_area(self):\n",
      "        self.assertEqual\n"
     ]
    }
   ],
   "source": [
    "code = '''\n",
    "def calculate_area(length, width):\n",
    "    return length * width\n",
    "\n",
    "length = float(input(\"Enter the length of the rectangle: \"))\n",
    "width = float(input(\"Enter the width of the rectangle: \"))\n",
    "area = calculate_area(length, width)\n",
    "print(f\"The area of the rectangle is: {area}\")\n",
    "    '''\n",
    "\n",
    "chain = prompt | hf \n",
    "\n",
    "descriptions = chain.invoke(code)\n",
    "print(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes, it contains functions. The functions are calculate_area() and print().\\\\n', 'The number of inputs and outputs are 2 and 1 respectively.\\\\n', 'Yes, it contains loops (for, while) and if-statements.\"']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "des = descriptions[295:]\n",
    "regex_pattern = r\"(\\d+\\.\\s.*?)(?=\\n\\n|##|\\n\\d+\\.|$)\"\n",
    "items = re.findall(regex_pattern, des, re.DOTALL)\n",
    "separated_sentences = []\n",
    "split_sentences = re.split(r'\\n?\\s*\\d+\\.\\s', items[0])\n",
    "split_sentences = [sentence for sentence in split_sentences if sentence]\n",
    "separated_sentences.extend(split_sentences)\n",
    "print(separated_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
